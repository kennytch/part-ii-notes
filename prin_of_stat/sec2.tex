\section{Asymptotic Theory for MLE}\label{sec:asymptotic-theory-for-mle}

\begin{itemize}
    \item convergence almost surely
    \item convergence in probability
    \item convergence in distribution
\end{itemize}

\begin{prop}
    convergence \hl{a.s. $\Rightarrow$ in prob $\Rightarrow$ in distribution}
\end{prop}

\begin{prop}[Continuous mapping theorem]
    $g$ continuous,\\ then \hl{$X_n \xrightarrow{a.s./P/d} X \Rightarrow g(X_n) \xrightarrow{a.s./P/d} g(X)$}
\end{prop}

\begin{prop}[Slutsky's lemma]
    $X_n \xrightarrow{d} X$, $Y_n \xrightarrow{d} c$ deterministic, then
    \begin{enumerate}
        \item $Y_n \xrightarrow{P} c$
        \item $X_n + Y_n \xrightarrow{d} X + c$
        \item $X_{n}Y_n \xrightarrow{d} cX$
        \item $\frac{X_n}{Y_n} \xrightarrow{d} \frac{X}{c}$ if $c \neq 0$
    \end{enumerate}
    Random matrices $(A_n)_{ij} \xrightarrow{P} A_{ij}$ deterministic, then
    \begin{enumerate}
        \item $A_{n}X_n \xrightarrow{d} AX$
    \end{enumerate}
\end{prop}

\begin{itemize}
    \item bounded in probability $O_P(1)$ ------ $\forall \epsilon > 0, \exists M(\epsilon), \sup_n\Pb(\norm{X_n} > M(\epsilon)) < \epsilon$
\end{itemize}

\begin{prop}
    $X_n \xrightarrow{d} X$, then $(X_n)$ bounded in probability
\end{prop}

\begin{prop}[Weak law of large numbers]
    $X_i$ i.i.d.\ , $Var(X) < \infty$ (unnecessary), then \hl{$\bar{X}_n = \frac{1}{n} \sum X_i \rightarrowp \Ex(X)$}
\end{prop}

\begin{thm}[Strong law of large numbers]
    $X_i$ i.i.d.\ ,$\Ex|X| < \infty$, then \hl{$\bar X_n \rightarrowas \Ex(X)$}
\end{thm}

\begin{thm}[Central limit theorem(1-d)]
    $X_i$ i.i.d.\ , $Var(X) = \sigma^2 < \infty$, then\\ \hl{$\sqrt{n}(\bar X_n - \Ex(X)) \rightarrowd \mathcal{N}(0, \sigma^2)$}
\end{thm}

\begin{itemize}
    \item $\mathcal{N}(\mu, \Sigma)$ ------ p.d.f.\ $\frac{1}{(2\pi)^{k/2} |\det(\Sigma)|^{1/2}} \exp\left( -\frac{1}{2}
    (x - \mu)^\top \Sigma^{-1}(x - \mu)\right)$
\end{itemize}

\begin{fact}
    $X \sim \mathcal{N}(\mu, \Sigma)$, then $\alpha^\top X \sim \mathcal{N}(\alpha^\top \mu, \alpha^\top\Sigma\alpha)$
\end{fact}

\begin{prop}
    $AX + b \sim \mathcal{N}(A\mu + b, A\Sigma A^\top)$
\end{prop}

\begin{prop}
    $\Sigma$ diagonal, $X_{(j)}$ independent
\end{prop}

\begin{thm}[Central limit theorem(n-d)]
    $X_i$ i.i.d.\ , $Cov(X) = \Sigma$ positive definite, then\\ \hl{$\sqrt{n}\left( \bar X_n  - \Ex(X)\right) \rightarrowd \mathcal{N}(0, \Sigma)$}
\end{thm}

\begin{itemize}
    \item asymptotic efficiency ------ $nVar_{\theta_0}(\tilde \theta_0) \rightarrow I^{-1}(\theta_0)$
\end{itemize}

\begin{fact}
    Under suitable assumptions, $\theta_{MLE} \approx \mathcal{N}(\theta, I^{-1}(\theta_0)/n)$
\end{fact}

\begin{example}[Confidence interval]\,
    \begin{itemize}
        \item confidence region $\mathcal{C}_n = \left\{ |\mu - \bar{X}| \leq \frac{\sigma z_\alpha}{\sqrt{n}} \right\}$
        \item asymptotic level $1 - \alpha$ confidence set
    \end{itemize}
\end{example}

\begin{setting}
    $X_i$ i.i.d.\ , arising from $\left\{ P_\theta \right\}$
\end{setting}

\begin{itemize}
    \item consistency ------ $\tilde \theta_n \xrightarrow{P_\theta} \theta_0$
\end{itemize}

\begin{assumption}[Usual regularity assumptions]
    $\left\{ f(\cdot, \theta) \right\}$ statistical model of p.d.f.\  or p.m.f.\ st
    \begin{enumerate}
        \item $f(x, \theta) > 0$
        \item $\int_{Xf(x, \theta)}dx = 1$
        \item $f(x, \cdot)$ continuous
        \item $\Theta$ compact
        \item $f(\cdot, \theta) = f(\cdot, \theta') \Rightarrow \theta = \theta'$
        \item $\Ex_{\theta}\sup_{\theta}|\log f(X, \theta)| < \infty$
    \end{enumerate}
\end{assumption}

\begin{thm}[Consistency of the MLE]
    Usual regularity assumptions, $X_i$ i.i.d.\ , then
    \begin{enumerate}
        \item MLE exists
        \item MLE consistent
    \end{enumerate}
\end{thm}

\begin{fact}
    proof can be simplified when $l_n$ differentiable, in this case $\Theta$ compact not needed
\end{fact}

\begin{thm}[Uniform law of large numbers]
    $\Theta$ compact, $q(x, \cdot)$ continuous, $\Ex\sup_\Theta|q(X, \theta)| < \infty$, then
    $\sup_\Theta |\frac{1}{n} \sum q(X_i, \theta) - \Ex(q(X, \theta))| \rightarrowas 0 $
\end{thm}

\begin{assumption}
    In addition to usual regularity assumption,
    \begin{enumerate}
        \item true $\theta_0 \in int(\Theta)$
        \item $\exists U$ open nbhd of $\theta_0$ st $f(x, \cdot) \in C^2$
        \item $I(\theta_0)$ non-singular, $\Ex_{\theta_0}\norm{\nabla_\theta \log f(X, \theta_0)} < \infty$
        \item $\exists K \subset U$ compact, non-empty interior containing $\theta_0$ st
        \begin{align*}
            \Ex_{\theta_0}\sup_K \norm{\nabla^2_\theta \log f(X, \theta)} < \infty \\
            \int_X \sup_K \norm{\nabla_\theta \log f(X, \theta)}dx < \infty\\
            \int_X \sup_K \norm{\nabla^2_\theta \log f(X, \theta)} dx < \infty
        \end{align*}
    \end{enumerate}
\end{assumption}

\begin{thm}
    Further usual assumption, $\hat{\theta_n}$ MLE of i.i.d.\ $X_i \sim P_{\theta_0}$, then\\
    $\sqrt{n}(\hat{\theta}_n - \theta_0) \rightarrowd \mathcal{N}(0, I(\theta_0)^{-1})$
\end{thm}

\begin{itemize}
    \item asymptotic efficiency ------ $n Var_{\theta_0}(\tilde \theta_n) \rightarrow I(\theta_0)^{-1}$
    \item Hodge estimator ------ $\tilde \theta_n = \begin{cases}
                                                        \hat \theta_n & \text{if } |\hat \theta_n| > n^{-1/4}\\
                                                        0 & \text{otherwise}
    \end{cases}$
    \item profile likelihood $L^{(p)}(\theta_1) = \sup_{\Theta_2} L((\theta_1, \theta_2))$
    \item plug-in MLE $\Phi(\hat \theta_{MLE})$
\end{itemize}

\begin{fact}
    under new parametrization $\left\{ f(\cdot, \phi) : \phi = \Phi(\theta) \right\}$, $\hat \phi_{MLE} = \Phi (\hat \theta_{MLE})$
\end{fact}

\begin{thm}[Delta method]
    $\Phi \in C^1$ at $\theta_0$, $\nabla_\theta \Phi(\theta_0) \neq 0$, let $(\hat \theta_n)$ st $\sqrt{n}(\hat \theta_n - \theta_0) \rightarrowd Z$, then\\
    $\sqrt{n} (\Phi(\hat \theta_n) - \Phi(\theta_0)) \rightarrowd \nabla_\theta \Phi(\theta_0)^\top Z$
\end{thm}

\begin{fact}
    if $\hat \theta_n$ MLE with asymptotic normality, then $\sqrt{n}(\Phi(\hat \theta_n) - \Phi(\theta_0)) \rightarrowd \mathcal{N}(0, \nabla_\theta \Phi(\theta_0)^\top I^{-1}(\theta_0) \nabla_\theta \Phi(\theta_0))$
\end{fact}

\begin{fact}
    plug in MLE asymptotically efficient
\end{fact}
